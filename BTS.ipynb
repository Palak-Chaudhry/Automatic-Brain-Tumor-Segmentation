{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "ccddc0e51f73d46bcaf670c19401b48674ee274c93c0d2c43fa9c9341a93c2d5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install -r requirements.txt"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 2)) (1.19.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 3)) (8.1.1)\n",
      "Requirement already satisfied: requests in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 4)) (2.25.1)\n",
      "Requirement already satisfied: torchsummary in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 5)) (1.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 6)) (4.61.1)\n",
      "Requirement already satisfied: torch in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 7)) (1.9.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 8)) (0.10.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from -r requirements.txt (line 9)) (3.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->-r requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->-r requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->-r requirements.txt (line 4)) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->-r requirements.txt (line 4)) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->-r requirements.txt (line 4)) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->-r requirements.txt (line 4)) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\palak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch->-r requirements.txt (line 7)) (3.7.4.3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\r\n",
    "import warnings\r\n",
    "import pickle\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "\r\n",
    "import torch\r\n",
    "from torch.utils.data import SubsetRandomSampler\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "import preprocess\r\n",
    "import unet as model\r\n",
    "import classifier\r\n",
    "#import bts.plot as plot\r\n",
    "\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "print('Computation Details')\r\n",
    "print(f'\\tDevice Used: ({device})\\n')\r\n",
    "\r\n",
    "print('Packages Used Versions:-')\r\n",
    "print(f'\\tPytorch Version: {torch.__version__}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Computation Details\n",
      "\tDevice Used: (cpu)\n",
      "\n",
      "Packages Used Versions:-\n",
      "\tPytorch Version: 1.9.0+cpu\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "TEST_SPLIT = 0.2\r\n",
    "DATASET_PATH = \"D:\\Palak\\Brain-Tumor-Segmentation\\BTS_Palak\\dataset\\png_dataset\"\r\n",
    "LOAD_MODEL = False\r\n",
    "FILTER_LIST = [16,32,64,128,256]\r\n",
    "EPOCHS = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def get_indices(length, new=False):\r\n",
    "    \"\"\" Gets the Training & Testing data indices for a\r\n",
    "    paticular \"DATASET_USED\".Stores the indices and returns\r\n",
    "    them back when the same dataset is used.\r\n",
    "    Parameters:\r\n",
    "        length(int): Length of the dataset used.\r\n",
    "        new(bool): Discard the saved indices and get new ones.\r\n",
    "    Return:\r\n",
    "        train_indices(list): Array of indices used for training purpose.\r\n",
    "        test_indices(list): Array of indices used for testing purpose.\r\n",
    "    \"\"\"\r\n",
    "    # Pickle file location of the indices.\r\n",
    "    file_path = os.path.join('D:\\Palak\\Brain-Tumor-Segmentation\\BTS_Palak\\dataset','split_indices_png_dataset')\r\n",
    "    data = dict()\r\n",
    "    if os.path.isfile(file_path) and not new:\r\n",
    "        # File found.\r\n",
    "        with open(file_path,'rb') as file :\r\n",
    "            data = pickle.load(file)\r\n",
    "            return data['train_indices'], data['test_indices']\r\n",
    "    else:\r\n",
    "        # File not found or fresh copy is required.\r\n",
    "        indices = list(range(length))\r\n",
    "        np.random.shuffle(indices)\r\n",
    "        split = int(np.floor(TEST_SPLIT * len(tumor_dataset)))\r\n",
    "        train_indices , test_indices = indices[split:], indices[:split]\r\n",
    "        # Indices are saved with pickle.\r\n",
    "        data['train_indices'] = train_indices\r\n",
    "        data['test_indices'] = test_indices\r\n",
    "        with open(file_path,'wb') as file:\r\n",
    "            pickle.dump(data,file)\r\n",
    "    return train_indices, test_indices"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "tumor_dataset = preprocess.TumorDataset(DATASET_PATH)\r\n",
    "\r\n",
    "train_indices, test_indices = get_indices(len(tumor_dataset))\r\n",
    "train_sampler, test_sampler = SubsetRandomSampler(train_indices), SubsetRandomSampler(test_indices)\r\n",
    "\r\n",
    "trainloader = torch.utils.data.DataLoader(tumor_dataset, 6, sampler=train_sampler)\r\n",
    "testloader = torch.utils.data.DataLoader(tumor_dataset, 1, sampler=test_sampler)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "unet_model = None\r\n",
    "unet_classifier = None\r\n",
    "if not LOAD_MODEL:\r\n",
    "    # New model is created.\r\n",
    "    unet_model = model.DynamicUNet(FILTER_LIST).to(device)\r\n",
    "    unet_classifier = classifier.BrainTumorClassifier(unet_model,device)\r\n",
    "else:\r\n",
    "    # Saved model is loaded on memory.\r\n",
    "    unet_model = model.DynamicUNet(FILTER_LIST)\r\n",
    "    unet_classifier = classifier.BrainTumorClassifier(unet_model,device)\r\n",
    "    unet_classifier.restore_model(os.path.join('saved_models',MODEL_NAME))\r\n",
    "    print('Saved model loaded')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "unet_model.train()\r\n",
    "MODEL_NAME = f\"UNet-{FILTER_LIST}.pt\"\r\n",
    "path = f\"saved_models/UNet-{FILTER_LIST}.pt\"\r\n",
    "unet_train_history = unet_classifier.train(EPOCHS,trainloader,mini_batch=100,save_best=path)\r\n",
    "print(f'Training Finished after {EPOCHS} epoches')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting Training Process\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4804/1901510367.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mMODEL_NAME\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"UNet-{FILTER_LIST}.pt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"saved_models/UNet-{FILTER_LIST}.pt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0munet_train_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munet_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_best\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Training Finished after {EPOCHS} epoches'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Palak\\Brain-Tumor-Segmentation\\BTS_Palak\\classifier.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, trainloader, mini_batch, learning_rate, save_best)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;31m# Training a single epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[0mepoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;31m# Reduce LR On Plateau\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Palak\\Brain-Tumor-Segmentation\\BTS_Palak\\classifier.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[1;34m(self, trainloader, mini_batch)\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[1;31m# Calculation predicted output using forward pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[1;31m# Calculating the loss value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Palak\\Brain-Tumor-Segmentation\\BTS_Palak\\unet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m#   Block 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mup9\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv8_t\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[0mconv9\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv9_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mup9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mconv9\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv9_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 439\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "unet_model.eval()\r\n",
    "unet_score = unet_classifier.test(testloader)\r\n",
    "print(f'\\n\\nDice Score {unet_score}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "save_plot = os.path.join('images',f'{MODEL_NAME}-loss_graph.png')\r\n",
    "plot.loss_graph(unet_train_history['train_loss'],save_plot)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run this cell repeatedly to see some results.\r\n",
    "image_index = test_indices[i]\r\n",
    "sample = tumor_dataset[image_index]\r\n",
    "image, mask, output, d_score = unet_classifier.predict(sample,0.65)\r\n",
    "title = f'Name: {image_index}.png   Dice Score: {d_score:.5f}'\r\n",
    "# save_path = os.path.join('images',f'{d_score:.5f}_{image_index}.png')\r\n",
    "plot.result(image,mask,output,title,save_path=None)\r\n",
    "i += 1\r\n",
    "if i >= len(test_indices):\r\n",
    "    i = 0 "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}